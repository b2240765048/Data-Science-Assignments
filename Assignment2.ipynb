{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-JsD4n549KSW"
   },
   "source": [
    "# **AIN 214 - PA1 - FALL 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jeu4gamv8uxb"
   },
   "source": [
    "**Student ID** : 2240765048\n",
    "\n",
    "**Name-Surname**   : Demir Emiroğlu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "so7UTKwA8ULy"
   },
   "source": [
    "**Deadline: 3.11.2025 (23:59:59)**\n",
    "\n",
    "**Submission:** Submit your Jupyter Notebooks via https://submit.cs.hacettepe.edu.tr/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l9crUPV39bKP"
   },
   "source": [
    "# **Necessary Imports**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 998,
   "metadata": {
    "id": "bDF8rpnv9kjd"
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import pandas as pd\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YzjmuhYk90CY"
   },
   "source": [
    "# **Notes:**\n",
    "\n",
    "* Use pandas dataframe (df) to load the data.\n",
    "\n",
    "* Use numpy or pandas operations for the requested tasks unless otherwise specified.\n",
    "\n",
    "* You can insert more cells if it is necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ErBKcN6KBvW8"
   },
   "source": [
    "# **PART 1: Flight Delays and Cancellations Dataset**\n",
    "\n",
    "The US Department of Transportation's Bureau of Transportation.\n",
    "\n",
    "**Dataset Path: \"datasets/flights_dataset/*.csv\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SdgQNea5raAd"
   },
   "source": [
    "- `flights.csv` contains the flight information\n",
    "\n",
    "| Variable   | Description                                          |\n",
    "|------------|------------------------------------------------------|\n",
    "| `year`, `month`, `day` | The time information of the flight |\n",
    "| `dep_time`   | Departure time (in the format hhmm) where`NA` corresponds to a cancelled flight        |\n",
    "| `sched_dep_time`    | Scheduled departure time                        |\n",
    "| `dep_delay`  | Departure delay, in minutes (negative for early)    |\n",
    "| `arr_time`  | Arrival time    |\n",
    "| `sched_arr_time`  | Scheduled arrival time    |\n",
    "| `arr_delay`  | Arrival delay, in minutes (negative for early)    |\n",
    "| `carrier`  | Carrier/airline code    |\n",
    "| `tailnum`  | Tail number of the plane    |\n",
    "| `origin`     | Origin airport where flight starts (IATA code)\n",
    "| `airline`    | Carrier/airline name                        |\n",
    "| `dest`       | Destination airport where flight lands (IATA code)  |\n",
    "| `air_time`    | The duration of flight (on air)                       |\n",
    "| `distance`    | The distance between origin and destination airports (miles)                        |\n",
    "| `hour`, `minute`, `time_hour`    | Time information of the flight                       \n",
    "\n",
    "- `flights_weather.csv` contains the same flight information as well as weather conditions such as\n",
    "\n",
    "| Variable   | Description                                           |\n",
    "|------------|-------------------------------------------------------|\n",
    "| `visib`      | Visibility (in miles)                                 |\n",
    "| `wind_gust`  | Wind gust speed (in mph)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6EYHKHQRn_dE"
   },
   "source": [
    "### Load & Inspect the Data (15 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6np-3NMyjOCp"
   },
   "source": [
    "Load `flights.csv` as `flights_df` and `flights_weather.csv` as `weather_df` by using pandas DataFrame. (2 pts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1004,
   "metadata": {
    "id": "pmawWZa2l21n"
   },
   "outputs": [],
   "source": [
    "# Load the data\n",
    "flights_df=pd.read_csv(\"datasets/flights_dataset/flights.csv\")\n",
    "weather_df=pd.read_csv(\"datasets/flights_dataset/flights_weather.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TppuOy1gl56u"
   },
   "source": [
    "Show the first and the last five rows of the datasets. (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1006,
   "metadata": {
    "id": "CcIKAgghmEbW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "0  2022      1    1       1.0            2359        2.0     604.0   \n",
      "1  2022      1    1       1.0            2250       71.0     242.0   \n",
      "2  2022      1    1      10.0            2355       15.0     759.0   \n",
      "3  2022      1    1      25.0            2350       35.0     606.0   \n",
      "4  2022      1    1      35.0            2349       46.0     616.0   \n",
      "\n",
      "   sched_arr_time  arr_delay carrier  flight tailnum origin dest  air_time  \\\n",
      "0             618      -14.0      UA     555  N405UA    SEA  IAH     221.0   \n",
      "1             142       60.0      AS      72  N265AK    SEA  FAI     193.0   \n",
      "2             730       29.0      AS     270  N274AK    SEA  ATL     261.0   \n",
      "3             550       16.0      AS       7  N281AK    SEA  ORD     193.0   \n",
      "4             545       31.0      UA     507  N426UA    PDX  ORD     196.0   \n",
      "\n",
      "   distance  hour  minute             time_hour                airline  \n",
      "0      1874    23      59  2022-01-01T23:00:00Z  United Air Lines Inc.  \n",
      "1      1533    22      50  2022-01-01T22:00:00Z   Alaska Airlines Inc.  \n",
      "2      2182    23      55  2022-01-01T23:00:00Z   Alaska Airlines Inc.  \n",
      "3      1721    23      50  2022-01-01T23:00:00Z   Alaska Airlines Inc.  \n",
      "4      1739    23      49  2022-01-01T23:00:00Z  United Air Lines Inc.  \n",
      "        year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "111371  2022      6   30       NaN            1155        NaN       NaN   \n",
      "111372  2022      6   30       NaN            1448        NaN       NaN   \n",
      "111373  2022      6   30       NaN            1751        NaN       NaN   \n",
      "111374  2022      6   30       NaN            1145        NaN       NaN   \n",
      "111375  2022      6   30       NaN             720        NaN       NaN   \n",
      "\n",
      "        sched_arr_time  arr_delay carrier  flight tailnum origin dest  \\\n",
      "111371            2033        NaN      UA     206     NaN    SEA  EWR   \n",
      "111372            1732        NaN      DL     323   N3759    SEA  LAX   \n",
      "111373            2352        NaN      DL     377  N898DN    SEA  ORD   \n",
      "111374            2029        NaN      DL     114  N876DN    SEA  JFK   \n",
      "111375            1544        NaN      DL     168  N814DN    SEA  BOS   \n",
      "\n",
      "        air_time  distance  hour  minute             time_hour  \\\n",
      "111371       NaN      2402    11      55  2022-06-30T11:00:00Z   \n",
      "111372       NaN       954    14      48  2022-06-30T14:00:00Z   \n",
      "111373       NaN      1721    17      51  2022-06-30T17:00:00Z   \n",
      "111374       NaN      2422    11      45  2022-06-30T11:00:00Z   \n",
      "111375       NaN      2496     7      20  2022-06-30T07:00:00Z   \n",
      "\n",
      "                      airline  \n",
      "111371  United Air Lines Inc.  \n",
      "111372   Delta Air Lines Inc.  \n",
      "111373   Delta Air Lines Inc.  \n",
      "111374   Delta Air Lines Inc.  \n",
      "111375   Delta Air Lines Inc.  \n"
     ]
    }
   ],
   "source": [
    "# flights_df\n",
    "print(flights_df.head())\n",
    "print(flights_df.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1007,
   "metadata": {
    "id": "cCNvWBN7mEpc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "0  2022      1    1       1.0            2359        2.0     604.0   \n",
      "1  2022      1    1       1.0            2250       71.0     242.0   \n",
      "2  2022      1    1      10.0            2355       15.0     759.0   \n",
      "3  2022      1    1      25.0            2350       35.0     606.0   \n",
      "4  2022      1    1      35.0            2349       46.0     616.0   \n",
      "\n",
      "   sched_arr_time  arr_delay carrier  ...    route  temp  dewp  humid  \\\n",
      "0             618      -14.0      UA  ...  SEA-IAH  33.0  23.0  66.06   \n",
      "1             142       60.0      AS  ...  SEA-FAI  32.0  23.0  69.04   \n",
      "2             730       29.0      AS  ...  SEA-ATL  33.0  23.0  66.06   \n",
      "3             550       16.0      AS  ...  SEA-ORD  33.0  23.0  66.06   \n",
      "4             545       31.0      UA  ...  PDX-ORD  33.0  19.0  55.75   \n",
      "\n",
      "   wind_dir  wind_speed  wind_gust  precip pressure visib  \n",
      "0     160.0     8.05546   9.270062     0.0   1022.9  10.0  \n",
      "1     170.0     9.20624  10.594357     0.0   1023.4  10.0  \n",
      "2     160.0     8.05546   9.270062     0.0   1022.9  10.0  \n",
      "3     160.0     8.05546   9.270062     0.0   1022.9  10.0  \n",
      "4     120.0     6.90468   7.945768     0.0   1025.1  10.0  \n",
      "\n",
      "[5 rows x 29 columns]\n",
      "        year  month  day  dep_time  sched_dep_time  dep_delay  arr_time  \\\n",
      "111001  2022      6   30       NaN            1155        NaN       NaN   \n",
      "111002  2022      6   30       NaN            1448        NaN       NaN   \n",
      "111003  2022      6   30       NaN            1751        NaN       NaN   \n",
      "111004  2022      6   30       NaN            1145        NaN       NaN   \n",
      "111005  2022      6   30       NaN             720        NaN       NaN   \n",
      "\n",
      "        sched_arr_time  arr_delay carrier  ...    route  temp  dewp  humid  \\\n",
      "111001            2033        NaN      UA  ...  SEA-EWR  56.0  51.0  83.88   \n",
      "111002            1732        NaN      DL  ...  SEA-LAX  60.0  53.0  77.65   \n",
      "111003            2352        NaN      DL  ...  SEA-ORD  65.0  53.0  65.56   \n",
      "111004            2029        NaN      DL  ...  SEA-JFK  56.0  51.0  83.88   \n",
      "111005            1544        NaN      DL  ...  SEA-BOS  56.0  50.0  80.52   \n",
      "\n",
      "        wind_dir  wind_speed  wind_gust  precip pressure visib  \n",
      "111001      30.0     9.20624  10.594357     0.0   1021.5  10.0  \n",
      "111002      20.0     6.90468   7.945768     0.0   1021.9  10.0  \n",
      "111003     280.0     6.90468   7.945768     0.0   1021.3  10.0  \n",
      "111004      30.0     9.20624  10.594357     0.0   1021.5  10.0  \n",
      "111005     350.0     5.75390   6.621473     0.0   1021.8  10.0  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "# weather\n",
    "print(weather_df.head())\n",
    "print(weather_df.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uORkqzdbmKiv"
   },
   "source": [
    "How many records(rows) exists on each dataset? Use print function for the answer. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1009,
   "metadata": {
    "id": "W1V1oCdNmXk7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows of flights dataset: 111376\n",
      "Number of rows of fligths_weather dataset: 111006\n"
     ]
    }
   ],
   "source": [
    "# Show the number of records (rows) in each dataset.\n",
    "print(\"Number of rows of flights dataset:\",len(flights_df))\n",
    "print(\"Number of rows of fligths_weather dataset:\",len(weather_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ccY3m3lIm2g8"
   },
   "source": [
    "What are the column types? Print columns and their datatypes. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {
    "id": "_aSVJKcZnAhw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year                int64\n",
      "month               int64\n",
      "day                 int64\n",
      "dep_time          float64\n",
      "sched_dep_time      int64\n",
      "dep_delay         float64\n",
      "arr_time          float64\n",
      "sched_arr_time      int64\n",
      "arr_delay         float64\n",
      "carrier            object\n",
      "flight              int64\n",
      "tailnum            object\n",
      "origin             object\n",
      "dest               object\n",
      "air_time          float64\n",
      "distance            int64\n",
      "hour                int64\n",
      "minute              int64\n",
      "airline            object\n",
      "route              object\n",
      "temp              float64\n",
      "dewp              float64\n",
      "humid             float64\n",
      "wind_dir          float64\n",
      "wind_speed        float64\n",
      "wind_gust         float64\n",
      "precip            float64\n",
      "pressure          float64\n",
      "visib             float64\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "# Show the data types for columns\n",
    "print(weather_df.dtypes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mPPeSjV7mdt8"
   },
   "source": [
    "Compute a missing value summary (count and %) per column for each dataset. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {
    "id": "cZb073HimuL9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flights_df dataset:\n",
      "Column:year, Missing Value:0, Percentage:0.0%\n",
      "Column:month, Missing Value:0, Percentage:0.0%\n",
      "Column:day, Missing Value:0, Percentage:0.0%\n",
      "Column:dep_time, Missing Value:2445, Percentage:2.195266484700474%\n",
      "Column:sched_dep_time, Missing Value:0, Percentage:0.0%\n",
      "Column:dep_delay, Missing Value:2445, Percentage:2.195266484700474%\n",
      "Column:arr_time, Missing Value:2542, Percentage:2.282358856486137%\n",
      "Column:sched_arr_time, Missing Value:0, Percentage:0.0%\n",
      "Column:arr_delay, Missing Value:2679, Percentage:2.405365608389599%\n",
      "Column:carrier, Missing Value:0, Percentage:0.0%\n",
      "Column:flight, Missing Value:0, Percentage:0.0%\n",
      "Column:tailnum, Missing Value:129, Percentage:0.11582387587990232%\n",
      "Column:origin, Missing Value:0, Percentage:0.0%\n",
      "Column:dest, Missing Value:0, Percentage:0.0%\n",
      "Column:air_time, Missing Value:2679, Percentage:2.405365608389599%\n",
      "Column:distance, Missing Value:0, Percentage:0.0%\n",
      "Column:hour, Missing Value:0, Percentage:0.0%\n",
      "Column:minute, Missing Value:0, Percentage:0.0%\n",
      "Column:time_hour, Missing Value:0, Percentage:0.0%\n",
      "Column:airline, Missing Value:0, Percentage:0.0%\n",
      "\n",
      "weather_df dataset:\n",
      "Column:year, Missing Value:0, Percentage:0.0%\n",
      "Column:month, Missing Value:0, Percentage:0.0%\n",
      "Column:day, Missing Value:0, Percentage:0.0%\n",
      "Column:dep_time, Missing Value:2440, Percentage:2.198079383096409%\n",
      "Column:sched_dep_time, Missing Value:0, Percentage:0.0%\n",
      "Column:dep_delay, Missing Value:2440, Percentage:2.198079383096409%\n",
      "Column:arr_time, Missing Value:2537, Percentage:2.285462047096553%\n",
      "Column:sched_arr_time, Missing Value:0, Percentage:0.0%\n",
      "Column:arr_delay, Missing Value:2674, Percentage:2.4088787993441794%\n",
      "Column:carrier, Missing Value:0, Percentage:0.0%\n",
      "Column:flight, Missing Value:0, Percentage:0.0%\n",
      "Column:tailnum, Missing Value:129, Percentage:0.11620993459812982%\n",
      "Column:origin, Missing Value:0, Percentage:0.0%\n",
      "Column:dest, Missing Value:0, Percentage:0.0%\n",
      "Column:air_time, Missing Value:2674, Percentage:2.4088787993441794%\n",
      "Column:distance, Missing Value:0, Percentage:0.0%\n",
      "Column:hour, Missing Value:0, Percentage:0.0%\n",
      "Column:minute, Missing Value:0, Percentage:0.0%\n",
      "Column:airline, Missing Value:0, Percentage:0.0%\n",
      "Column:route, Missing Value:0, Percentage:0.0%\n",
      "Column:temp, Missing Value:0, Percentage:0.0%\n",
      "Column:dewp, Missing Value:0, Percentage:0.0%\n",
      "Column:humid, Missing Value:0, Percentage:0.0%\n",
      "Column:wind_dir, Missing Value:3163, Percentage:2.8493955281696484%\n",
      "Column:wind_speed, Missing Value:279, Percentage:0.25133776552618775%\n",
      "Column:wind_gust, Missing Value:279, Percentage:0.25133776552618775%\n",
      "Column:precip, Missing Value:0, Percentage:0.0%\n",
      "Column:pressure, Missing Value:0, Percentage:0.0%\n",
      "Column:visib, Missing Value:0, Percentage:0.0%\n"
     ]
    }
   ],
   "source": [
    "# Print the summary\n",
    "print(\"flights_df dataset:\")\n",
    "for column in flights_df.columns:\n",
    "    number_of_missing_val=flights_df[column].isna()\n",
    "    count=number_of_missing_val.sum()\n",
    "    percentage=(count/len(flights_df[column]))*100\n",
    "    print(f\"Column:{column}, Missing Value:{count}, Percentage:{percentage}%\")\n",
    "print(\"\\nweather_df dataset:\")\n",
    "for column in weather_df.columns:\n",
    "    number_of_missing_val=weather_df[column].isna()\n",
    "    count=number_of_missing_val.sum()\n",
    "    percentage=(count/len(weather_df[column]))*100\n",
    "    print(f\"Column:{column}, Missing Value:{count}, Percentage:{percentage}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "juLxl7Iv0ONj"
   },
   "source": [
    "Identify likely key columns for a potential merging between two datasets. (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1015,
   "metadata": {
    "id": "Y6na0EQw0WHS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "year,month,day,dep_time,sched_dep_time,dep_delay,arr_time,sched_arr_time,arr_delay,carrier,flight,tailnum,origin,dest,air_time,distance,hour,minute,airline\n"
     ]
    }
   ],
   "source": [
    "# Answer here\n",
    "column_names_flightsdf=[]\n",
    "same_column_names=[]\n",
    "for column_name in flights_df.columns:\n",
    "    column_names_flightsdf.append(column_name)\n",
    "for column_name in weather_df.columns:\n",
    "    if column_name in column_names_flightsdf:\n",
    "        same_column_names.append(column_name)\n",
    "print(\",\".join(same_column_names))\n",
    "# EXPLANATION: Columns with same names in two different datasets can be used to combine or exchange of information through datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UV_EhjXev6xM"
   },
   "source": [
    "### Data Exploration and Analysis (35 pts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G97mdVU-20AZ"
   },
   "source": [
    "**Note:** You can create new columns, merge datasets or perform any other operations in this stage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yb4aFthhwIP8"
   },
   "source": [
    "How many different airlines has flight records in the flights dataset? (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1019,
   "metadata": {
    "id": "LsgxqBP8v-Jm"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "name_of_airlines=[]\n",
    "for airline_name in flights_df[\"airline\"]:\n",
    "    if airline_name not in name_of_airlines:\n",
    "        name_of_airlines.append(airline_name)\n",
    "print(len(name_of_airlines))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_2VZ_8w1wcUl"
   },
   "source": [
    "Calculate the mean, min, max and std of the departure delay times. (Column: `dep_delay`) (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1021,
   "metadata": {
    "id": "CB8wUFXAxBvr"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean: 8.036674592173027\n",
      "min: -36.0\n",
      "max: 2120.0\n",
      "std: 41.65103180286961\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "print(\"mean:\",flights_df[\"dep_delay\"].mean())\n",
    "print(\"min:\",flights_df[\"dep_delay\"].min())\n",
    "print(\"max:\",flights_df[\"dep_delay\"].max())\n",
    "print(\"std:\",flights_df[\"dep_delay\"].std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p6aZ5m-xxCWb"
   },
   "source": [
    "Compute the summary statistics for weather columns. (`temperature`, `wind_speed`, `precipitation`) (2 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1023,
   "metadata": {
    "id": "R-YJEIM80wn6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>temp</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>precip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>111006.000000</td>\n",
       "      <td>110727.000000</td>\n",
       "      <td>111006.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>48.155538</td>\n",
       "      <td>6.995307</td>\n",
       "      <td>0.005774</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.363201</td>\n",
       "      <td>4.507431</td>\n",
       "      <td>0.022099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>21.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>4.603120</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>47.000000</td>\n",
       "      <td>6.904680</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>54.000000</td>\n",
       "      <td>9.206240</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>99.000000</td>\n",
       "      <td>27.618720</td>\n",
       "      <td>0.320000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                temp     wind_speed         precip\n",
       "count  111006.000000  110727.000000  111006.000000\n",
       "mean       48.155538       6.995307       0.005774\n",
       "std         9.363201       4.507431       0.022099\n",
       "min        21.900000       0.000000       0.000000\n",
       "25%        42.000000       4.603120       0.000000\n",
       "50%        47.000000       6.904680       0.000000\n",
       "75%        54.000000       9.206240       0.000000\n",
       "max        99.000000      27.618720       0.320000"
      ]
     },
     "execution_count": 1023,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Answer the question above\n",
    "weather_df[[\"temp\",\"wind_speed\",\"precip\"]].describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fr015Lpa0xF0"
   },
   "source": [
    "How many flights are delayed more than 15 minutes? Report count and the percentage. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {
    "id": "djddId1m2yPo"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "count: 17539\n",
      "percentage: 15.74755782215199 %\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "flights_over15=flights_df[\"dep_delay\"]>15\n",
    "count=flights_over15.sum()\n",
    "percentage=(count/len(flights_df[\"dep_delay\"]))*100\n",
    "print(\"count:\",count)\n",
    "print(\"percentage:\",percentage,\"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5tf7EL112y4N"
   },
   "source": [
    "How many flights are cancelled in the dataset? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1027,
   "metadata": {
    "id": "nqHPds9Q3JB7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2445\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "cancelled_flights=flights_df[\"dep_time\"].isna()\n",
    "number_of_cancelled_flights=cancelled_flights.sum()\n",
    "print(number_of_cancelled_flights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JkSTYCxT3IVt"
   },
   "source": [
    "Report top 5 airlines has the most cancellation by count and percantage seperately. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1029,
   "metadata": {
    "id": "ywsU-3xR3XkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska Airlines Inc.\n",
      "Delta Air Lines Inc.\n",
      "Horizon Air\n",
      "SkyWest Airlines Inc.\n",
      "Southwest Airlines Co.\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "airline_cancellation_dict={}\n",
    "for i,row in flights_df.iterrows():\n",
    "    cancellation=row[\"dep_time\"]\n",
    "    airline=row[\"airline\"]\n",
    "    if pd.isna(cancellation):\n",
    "        if airline not in airline_cancellation_dict:\n",
    "            airline_cancellation_dict[airline]=1\n",
    "        else:\n",
    "            airline_cancellation_dict[airline]+=1\n",
    "count_list=[]\n",
    "for name,count in airline_cancellation_dict.items():\n",
    "    count_list.append(count)\n",
    "sorted_count_list=sorted(count_list,reverse=True)\n",
    "\n",
    "for i in range(5):\n",
    "    for airline,count in airline_cancellation_dict.items():\n",
    "        if count==sorted_count_list[i]:\n",
    "            print(airline)\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1030,
   "metadata": {
    "id": "VTkFMUFp3XVz"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alaska Airlines Inc.\n",
      "Delta Air Lines Inc.\n",
      "Horizon Air\n",
      "SkyWest Airlines Inc.\n",
      "Southwest Airlines Co.\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "airline_cancellation_dict={}\n",
    "for i,row in flights_df.iterrows():\n",
    "    cancellation=row[\"dep_time\"]\n",
    "    airline=row[\"airline\"]\n",
    "    if pd.isna(cancellation):\n",
    "        if airline not in airline_cancellation_dict:\n",
    "            airline_cancellation_dict[airline]=1\n",
    "        else:\n",
    "            airline_cancellation_dict[airline]+=1\n",
    "\n",
    "total_number_of_cancellation=flights_df[\"dep_time\"].isna().sum()\n",
    "for airline,count in airline_cancellation_dict.items():\n",
    "    percentage=(count/total_number_of_cancellation)*100\n",
    "    airline_cancellation_dict[airline]=percentage\n",
    "\n",
    "count_list=[]\n",
    "for name,count in airline_cancellation_dict.items():\n",
    "    count_list.append(count)\n",
    "sorted_count_list=sorted(count_list,reverse=True)\n",
    "\n",
    "for i in range(5):\n",
    "    for airline,count in airline_cancellation_dict.items():\n",
    "        if count==sorted_count_list[i]:\n",
    "            print(airline)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IEgm1g9K3fxJ"
   },
   "source": [
    "Which airline has the highest departure delay average? And what is the average delay for the airline? (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1032,
   "metadata": {
    "id": "FxLH9CSa3quw"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Airline: JetBlue Airways / Delay: 42.14152410575428\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "airline_delay_dict={}\n",
    "airline_flight_count_dict={}\n",
    "for i,row in flights_df.iterrows():\n",
    "    delay=row[\"dep_delay\"]\n",
    "    airline=row[\"airline\"]\n",
    "    if not pd.isna(delay):\n",
    "        if airline not in airline_delay_dict:\n",
    "            airline_delay_dict[airline]=delay\n",
    "            airline_flight_count_dict[airline]=1\n",
    "        else:\n",
    "            airline_delay_dict[airline]+=delay\n",
    "            airline_flight_count_dict[airline]+=1\n",
    "for airline in airline_delay_dict:\n",
    "    airline_delay_dict[airline]=airline_delay_dict[airline]/airline_flight_count_dict[airline]\n",
    "highest_average=max(airline_delay_dict.values())\n",
    "for airline,avg_delay in airline_delay_dict.items():\n",
    "    if avg_delay==highest_average:\n",
    "        print(\"Airline:\",airline,\"/ Delay:\",avg_delay)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aX7IWTLK3rQT"
   },
   "source": [
    "Which routes has the most cancelled flights? Report top 10 routes and the number of cancelled flights. (Note: A route is \"[origin]-[dest]\". For example PDX-BUR) (4 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {
    "id": "q7u7AUf-4JYS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route: SEA - LAX  Number: 93\n",
      "Route: SEA - ANC  Number: 78\n",
      "Route: SEA - LAS  Number: 73\n",
      "Route: SEA - LAS  Number: 73\n",
      "Route: SEA - PDX  Number: 71\n",
      "Route: SEA - JFK  Number: 70\n",
      "Route: PDX - SEA  Number: 68\n",
      "Route: SEA - DEN  Number: 66\n",
      "Route: SEA - ORD  Number: 63\n",
      "Route: SEA - PHX  Number: 60\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "routes={}\n",
    "for i,row in flights_df.iterrows():\n",
    "    route=row[\"origin\"],row[\"dest\"]\n",
    "    time=row[\"dep_time\"]\n",
    "    if pd.isna(row[\"origin\"]) or pd.isna(row[\"dest\"]):\n",
    "        continue\n",
    "    if route not in routes and pd.isna(time):\n",
    "        routes[route]=1\n",
    "    elif route in routes and pd.isna(time):\n",
    "        routes[route]+=1\n",
    "count_list=[]\n",
    "for flight,count in routes.items():\n",
    "    count_list.append(count)\n",
    "sorted_count_list=sorted(count_list,reverse=True)\n",
    "    \n",
    "for i in range(10):\n",
    "    for route,count in routes.items():\n",
    "        if count==sorted_count_list[i]:\n",
    "            print(\"Route:\",route[0],\"-\",route[1],\" Number:\",count)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zdsRWPsT4P0k"
   },
   "source": [
    "Which route has the highest average departure delay time? Report top 10 routes with the average departure delay times. (3 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {
    "id": "DhBm5Ong4dkY"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Route: PDX - DSM  Delay: 35.78260869565217\n",
      "Route: PDX - GRR  Delay: 35.73913043478261\n",
      "Route: PDX - FLL  Delay: 30.893617021276597\n",
      "Route: SEA - MIA  Delay: 29.916666666666668\n",
      "Route: SEA - CLT  Delay: 27.313199105145415\n",
      "Route: PDX - STL  Delay: 27.0\n",
      "Route: PDX - BOS  Delay: 24.8125\n",
      "Route: PDX - DFW  Delay: 24.7359413202934\n",
      "Route: PDX - DAL  Delay: 24.1\n",
      "Route: PDX - JFK  Delay: 21.729433272394882\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "route_delay_dict={}\n",
    "route_count_dict={}\n",
    "for i,row in flights_df.iterrows():\n",
    "    route=row[\"origin\"],row[\"dest\"]\n",
    "    delay=row[\"dep_delay\"]\n",
    "    if pd.isna(row[\"origin\"]) or pd.isna(row[\"dest\"]) or pd.isna(delay):\n",
    "        continue   \n",
    "    if route not in route_delay_dict:\n",
    "        route_delay_dict[route]=delay\n",
    "        route_count_dict[route]=1\n",
    "    else:\n",
    "        route_delay_dict[route]+=delay\n",
    "        route_count_dict[route]+=1\n",
    "for route in route_delay_dict:\n",
    "    route_delay_dict[route]=route_delay_dict[route]/route_count_dict[route]\n",
    "\n",
    "count_list=[]\n",
    "for route,count in route_delay_dict.items():\n",
    "    count_list.append(count)\n",
    "sorted_count_list=sorted(count_list,reverse=True)\n",
    "    \n",
    "for i in range(10):\n",
    "    for route,count in route_delay_dict.items():\n",
    "        if count==sorted_count_list[i]:\n",
    "            print(\"Route:\",route[0],\"-\",route[1],\" Delay:\",count)\n",
    "            break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9rZ-cM1j4nLv"
   },
   "source": [
    "Compare mean departure delay between rainy and non-rainy flights. (5 pts)\n",
    "\n",
    "Tip: Check `precip` column in weather dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {
    "id": "8RUXliFb45fV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean departure delay of rainy flights: 10.030634573304157\n",
      "Mean departure delay of non-rainy flights: 7.424000289247234\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "weather_delay_dict={\"Rainy\":0,\"Non-rainy\":0}\n",
    "count_dict={\"Rainy\":0,\"Non-rainy\":0}\n",
    "for i,row in weather_df.iterrows():\n",
    "    rain=row[\"precip\"]\n",
    "    delay=row[\"dep_delay\"]\n",
    "    if rain!=0 and not pd.isna(delay):\n",
    "        weather_delay_dict[\"Rainy\"]+=delay\n",
    "        count_dict[\"Rainy\"]+=1\n",
    "    elif rain==0 and not pd.isna(delay):\n",
    "        weather_delay_dict[\"Non-rainy\"]+=delay\n",
    "        count_dict[\"Non-rainy\"]+=1\n",
    "mean_delay_rainy=weather_delay_dict[\"Rainy\"]/count_dict[\"Rainy\"]\n",
    "mean_delay_nonrainy=weather_delay_dict[\"Non-rainy\"]/count_dict[\"Non-rainy\"]\n",
    "print(\"Mean departure delay of rainy flights:\",mean_delay_rainy)\n",
    "print(\"Mean departure delay of non-rainy flights:\",mean_delay_nonrainy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NDh0LxIL5Bfe"
   },
   "source": [
    "Compare mean departure delay between wind condition. Consider 10 mile per hour or more wind gust is considered as windy. (5 pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {
    "id": "EvFyQgj56JZh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean departure delay of windy flights: 9.216318104299434\n",
      "Mean departure delay of non-rainy flights: 7.5045880137306495\n"
     ]
    }
   ],
   "source": [
    "# Answer the question above\n",
    "wind_delay_dict={\"Windy\":0,\"Non-windy\":0}\n",
    "count_dict={\"Windy\":0,\"Non-windy\":0}\n",
    "for i,row in weather_df.iterrows():\n",
    "    wind=row[\"wind_gust\"]\n",
    "    delay=row[\"dep_delay\"]\n",
    "    if not pd.isna(wind) and wind>=10 and not pd.isna(delay):\n",
    "        wind_delay_dict[\"Windy\"]+=delay\n",
    "        count_dict[\"Windy\"]+=1\n",
    "    elif not pd.isna(wind) and wind<10 and not pd.isna(delay):\n",
    "        wind_delay_dict[\"Non-windy\"]+=delay\n",
    "        count_dict[\"Non-windy\"]+=1\n",
    "mean_delay_windy=wind_delay_dict[\"Windy\"]/count_dict[\"Windy\"]\n",
    "mean_delay_nonwindy=wind_delay_dict[\"Non-windy\"]/count_dict[\"Non-windy\"]\n",
    "print(\"Mean departure delay of windy flights:\",mean_delay_windy)\n",
    "print(\"Mean departure delay of non-rainy flights:\",mean_delay_nonwindy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_3suDJgQZm01"
   },
   "source": [
    "# **PART- 2**\n",
    "\n",
    "**SQL Questions**\n",
    "\n",
    "**You must use sqlite3 library for SQL operations**\n",
    "\n",
    "**Dataset Url: https://www.kaggle.com/datasets/ayeshaimran123/foodpanda-order-and-delivery-trends**\n",
    "\n",
    "\n",
    "The Foodpanda Order & Delivery Trends dataset contains information about customer orders made through the Foodpanda application. It includes details such as customer information, order status, restaurant data, ratings, payment methods, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DOZouTkQh-aa"
   },
   "source": [
    "Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8g3KN0RagrO4"
   },
   "source": [
    "# Tables\n",
    "\n",
    "## 1. Customer Table\n",
    "\n",
    "| Column          | Type    | Key         | Description                                                                                              |\n",
    "|-----------------|---------|-------------|----------------------------------------------------------------------------------------------------------|\n",
    "| customer_id     | TEXT    | PRIMARY KEY | Unique identifier for each customer                                                                      |\n",
    "| gender          | TEXT    |             | Gender of the customer                                                                                   |\n",
    "| age_group       | TEXT    |             | Categorizes customers into broad age-based segments                                                      |\n",
    "| city            | TEXT    |             | Indicates the city where customer resides                                                                |\n",
    "| signup_date     | TEXT    |             | Represents the date when the customers created their account on Foodpanda platform                       |\n",
    "| order_frequency | INTEGER |             | nIdicates how frequently customer places orders                                                          |\n",
    "| last_order_date | TEXT    |             | Date of last order                                                                                       |\n",
    "| loyalty_points  | INTEGER |             | Represents the reward points earned by a customer                                                        |\n",
    "| churned         | TEXT    |             | nIdicates whether customer has stopped using the Foodpanda platform after a certain period of inactivity |\n",
    "\n",
    "\n",
    "\n",
    "## 2. Order Table\n",
    "\n",
    "| Column          | Type    | Key     | Description                                                                                                                                                |\n",
    "| --------------- | ------- | ------- | ---------------------------------------------------------------------------------------------------------------------------------------------------------- |\n",
    "| order_id        | TEXT    | PRIMARY | Unique identifier for orders                                                                                                                               |\n",
    "| customer_id     | TEXT    | FOREIGN | Unique identifier for customers                                                                                                                            |\n",
    "| restaurant_id   | INTEGER | FOREIGN | Unique identifier for restaurants                                                                                                                          |\n",
    "| order_date      | TEXT    |         | Date of order                                                                                                                                              |\n",
    "| dish_name       | TEXT    |         | Indicates the type of the food item ordered by the customer                                                                                                |\n",
    "| category        | TEXT    |         | Represents the cusine of the ordered dish                                                                                                                  |\n",
    "| quantity        | INTEGER |         | Indicates the number of units of a particular dish ordered by the customer in a single order                                                               |\n",
    "| price           | REAL    |         | Represents the total cost of the ordered dish                                                                                                              |\n",
    "| payment_method  | TEXT    |         | Specifies the method used by the customer to pay for the order                                                                                             |\n",
    "| rating          | INTEGER |         | Indicates the numerical rating (usually on a scale such as 1–5) given by the customer to evaluate their satisfaction with the order or delivery experience |\n",
    "| rating_date     | TEXT    |         | Represents the date when the customer submitted their rating or review for the order                                                                       |\n",
    "| delivery_status | TEXT    |         | Describes the final status of the order’s delivery process                                                                                                 |\n",
    "\n",
    "\n",
    "## 3. Restaurant Table\n",
    "\n",
    "| Column          | Type    | Key     | Description                        |\n",
    "|-----------------|---------|---------|------------------------------------|\n",
    "| restaurant_id   | INTEGER | PRIMARY | Unique indetifiers for restaurants |\n",
    "| restaurant_name | TEXT    |         | Name of the restaurant             |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nWvMCCPLi2W0"
   },
   "source": [
    "**Dataset path: Data/Foodpanda Analysis Dataset.csv**\n",
    "\n",
    "In this section, you will work with the Foodpanda Order & Delivery Trends dataset, which stores information about orders made on the Foodpanda platform. You are required to read the dataset from a CSV file, build a relational database, and write code to answer the following questions. When creating the database, you must follow the table schema described above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lw6VazWW_jex"
   },
   "source": [
    "# Questions (50p)\n",
    "\n",
    "1. Read the csv file and create database. (10p)\n",
    "2. Find the top 3 restaurants with the highest total revenue. (revenue = quantity x price) (5p)\n",
    "3. Calculate the total quantity of dishes sold by category for each restaurant. (5p)\n",
    "4. List the top 5 customer with highest total spending (also show total spending value) (5p)\n",
    "5. Find the average rating for each restaurant. (5p)\n",
    "6. Check for duplicate orders (same customer_id+restaurant_id+order_date). (5p)\n",
    "7. Find the percentage of orders by delivery status. (7p)\n",
    "8. Analyze whether specific cities contribute a significantly larger portion to the total revenue compared to others. (8p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {
    "id": "MUWbll4RluQg"
   },
   "outputs": [],
   "source": [
    "#1\n",
    "df = pd.read_csv(\"Data/Foodpanda Analysis Dataset.csv\")\n",
    "connect = sqlite3.connect(\"foodpanda_analysis_database.db\")\n",
    "cursor = connect.cursor()\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Orders\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Customer\")\n",
    "cursor.execute(\"DROP TABLE IF EXISTS Restaurant\")\n",
    "\n",
    "cursor.execute(\"\"\"CREATE TABLE Customer(\n",
    "    customer_id TEXT PRIMARY KEY,\n",
    "    gender TEXT,\n",
    "    age TEXT,\n",
    "    city TEXT,\n",
    "    signup_date TEXT,\n",
    "    order_frequency INTEGER,\n",
    "    last_order_date TEXT,\n",
    "    loyalty_points INTEGER,\n",
    "    churned TEXT)\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE Restaurant (\n",
    "    restaurant_id INTEGER PRIMARY KEY,\n",
    "    restaurant_name TEXT)\"\"\")\n",
    "cursor.execute(\"\"\"CREATE TABLE Orders (\n",
    "    order_id TEXT PRIMARY KEY,\n",
    "    customer_id TEXT,\n",
    "    restaurant_id INTEGER,\n",
    "    order_date TEXT,\n",
    "    dish_name TEXT,\n",
    "    category TEXT,\n",
    "    quantity INTEGER,\n",
    "    price REAL,\n",
    "    payment_method TEXT,\n",
    "    rating INTEGER,\n",
    "    rating_date TEXT,\n",
    "    delivery_status TEXT,\n",
    "    FOREIGN KEY (customer_id) REFERENCES Customer(customer_id),\n",
    "    FOREIGN KEY (restaurant_id) REFERENCES Restaurant(restaurant_id))\"\"\")\n",
    "\n",
    "cust_data = df[['customer_id', 'gender', 'age', 'city', 'signup_date','order_frequency', 'last_order_date', 'loyalty_points', 'churned']].drop_duplicates(subset=['customer_id'])\n",
    "cust_data.to_sql('Customer', connect, if_exists='append', index=False)\n",
    "\n",
    "rest_ids = {}\n",
    "for i, name in enumerate(df['restaurant_name'].unique()):\n",
    "    rest_ids[name] = i + 1\n",
    "\n",
    "rest_data = pd.DataFrame({'restaurant_id': list(rest_ids.values()),'restaurant_name': list(rest_ids.keys())})\n",
    "rest_data.to_sql('Restaurant', connect, if_exists='append', index=False)\n",
    "df['restaurant_id'] = df['restaurant_name'].map(rest_ids)\n",
    "\n",
    "order_data = df[['order_id', 'customer_id', 'restaurant_id', 'order_date','dish_name', 'category', 'quantity', 'price', 'payment_method','rating', 'rating_date', 'delivery_status']]\n",
    "order_data.to_sql('Orders', connect, if_exists='append', index=False)\n",
    "\n",
    "connect.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {
    "id": "uy8mEErq_jex"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Pizza Hut', 3002380.59), ('Subway', 2998014.27), ('KFC', 2954233.45)]"
      ]
     },
     "execution_count": 1047,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#2\n",
    "cursor.execute(\"\"\"SELECT restaurant_name,ROUND(sum(quantity*price),2)\n",
    "                  FROM Orders,Restaurant \n",
    "                  WHERE Orders.restaurant_id=Restaurant.restaurant_id \n",
    "                  GROUP BY restaurant_name \n",
    "                  ORDER BY sum(quantity*price) DESC \n",
    "                  LIMIT 3\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {
    "id": "GDkuTjVB_jex"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Burger King', 'Fast Food', 799),\n",
       " ('Burger King', 'Continental', 689),\n",
       " ('Burger King', 'Italian', 681),\n",
       " ('Burger King', 'Dessert', 658),\n",
       " ('Burger King', 'Chinese', 649),\n",
       " ('KFC', 'Continental', 757),\n",
       " ('KFC', 'Chinese', 754),\n",
       " ('KFC', 'Fast Food', 747),\n",
       " ('KFC', 'Italian', 735),\n",
       " ('KFC', 'Dessert', 641),\n",
       " (\"McDonald's\", 'Italian', 699),\n",
       " (\"McDonald's\", 'Fast Food', 686),\n",
       " (\"McDonald's\", 'Continental', 665),\n",
       " (\"McDonald's\", 'Chinese', 658),\n",
       " (\"McDonald's\", 'Dessert', 651),\n",
       " ('Pizza Hut', 'Continental', 803),\n",
       " ('Pizza Hut', 'Chinese', 801),\n",
       " ('Pizza Hut', 'Dessert', 746),\n",
       " ('Pizza Hut', 'Italian', 738),\n",
       " ('Pizza Hut', 'Fast Food', 638),\n",
       " ('Subway', 'Italian', 859),\n",
       " ('Subway', 'Fast Food', 746),\n",
       " ('Subway', 'Continental', 730),\n",
       " ('Subway', 'Dessert', 715),\n",
       " ('Subway', 'Chinese', 705)]"
      ]
     },
     "execution_count": 1103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3\n",
    "cursor.execute(\"\"\"SELECT restaurant_name,category,sum(quantity) \n",
    "                  FROM Orders,Restaurant \n",
    "                  WHERE Orders.restaurant_id=Restaurant.restaurant_id \n",
    "                  GROUP BY restaurant_name,category \n",
    "                  ORDER BY restaurant_name,SUM(quantity) DESC\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {
    "id": "HDkYUWUA_jey"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('C3134', 7496.85),\n",
       " ('C2515', 7495.05),\n",
       " ('C6021', 7494.65),\n",
       " ('C2857', 7493.6),\n",
       " ('C3320', 7491.8)]"
      ]
     },
     "execution_count": 1105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#4\n",
    "cursor.execute(\"\"\"SELECT customer_id,ROUND(sum(price*quantity),2) as total_price\n",
    "                  FROM Orders \n",
    "                  GROUP BY customer_id \n",
    "                  ORDER BY total_price DESC \n",
    "                  LIMIT 5\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {
    "id": "6WJ59Wag_jey"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Burger King', 2.97),\n",
       " ('KFC', 2.97),\n",
       " (\"McDonald's\", 3.0),\n",
       " ('Pizza Hut', 2.95),\n",
       " ('Subway', 3.09)]"
      ]
     },
     "execution_count": 1050,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#5\n",
    "cursor.execute(\"\"\"SELECT restaurant_name,ROUND(AVG(rating),2) \n",
    "                  FROM Orders,Restaurant \n",
    "                  WHERE Orders.restaurant_id=Restaurant.restaurant_id \n",
    "                  GROUP BY Restaurant.restaurant_name\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {
    "id": "2A86iBk2_jey"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#6\n",
    "cursor.execute(\"\"\"SELECT customer_id,restaurant_id,order_date \n",
    "                  FROM Orders \n",
    "                  GROUP BY customer_id,restaurant_id,order_date \n",
    "                  HAVING COUNT(order_id)>1\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {
    "id": "S4DVXq5r_jey"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Cancelled', 32.8), ('Delayed', 32.87), ('Delivered', 34.33)]"
      ]
     },
     "execution_count": 1085,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#7\n",
    "cursor.execute(\"\"\"SELECT delivery_status,ROUND(COUNT(delivery_status)*100.0/(SELECT COUNT(delivery_status) FROM Orders),2) \n",
    "                  FROM Orders \n",
    "                  GROUP BY delivery_status\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {
    "id": "ZYHl2joP_jey"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('Multan', 21.28),\n",
       " ('Lahore', 20.33),\n",
       " ('Peshawar', 20.26),\n",
       " ('Islamabad', 19.77),\n",
       " ('Karachi', 18.36)]"
      ]
     },
     "execution_count": 1053,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#8\n",
    "cursor.execute(\"\"\"SELECT city,ROUND(SUM(quantity*price)*100.0/(SELECT SUM(quantity*price) FROM Orders),2) AS percentage \n",
    "                  FROM Customer,Orders \n",
    "                  WHERE Customer.customer_id=Orders.customer_id \n",
    "                  GROUP BY city \n",
    "                  ORDER BY percentage DESC\"\"\")\n",
    "cursor.fetchall()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fTXBu8Dql0Iv"
   },
   "source": [
    "# PLAGIARISM\n",
    "\n",
    "All work on assignments must be done individually. You are encouraged to discuss the given assignments with your classmates, but these discussions should be carried out in an abstract way. That is, discussions related to a particular solution to a specific probem (either in actual code or in pseudocode) will not be tolerated. In short, turning in someone else’s work (including work available on the internet), in whole or in part, as your own will be considered as a violation of academic integrity. Please note that the former conditions also hold for the material attained using AI tools, including ChatGPT, GitHub Copilot, etc."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
